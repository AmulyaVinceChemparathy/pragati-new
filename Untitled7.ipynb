{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu73GJ+H5HKiSgCC83ioKq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmulyaVinceChemparathy/pragati-new/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pyttsx3\n",
        "from PIL import ImageGrab\n",
        "import pytesseract\n",
        "import cv2\n",
        "import time\n",
        "import keyboard\n",
        "import pygetwindow as gw\n",
        "\n",
        "# Initialize the text-to-speech engine\n",
        "\n",
        "engine = pyttsx3.init()\n",
        "\n",
        "# Configure the text-to-speech engine\n",
        "engine.setProperty('rate', 200)  # Speed of speech\n",
        "\n",
        "# Set the path to Tesseract OCR executable (you may need to change this)\n",
        "tesseract_path = r'C:\\Users\\USER\\AI_ML_DL Programs & Codes'\n",
        "pytesseract.pytesseract.tesseract_cmd = os.path.join(tesseract_path, 'tesseract.exe')\n",
        "\n",
        "# Set the path to the \"NC_images\" folder\n",
        "nc_images_path = os.path.join(tesseract_path, 'NC_images')\n",
        "\n",
        "# Function to perform OCR on the selected region and read the text aloud\n",
        "def read_text(selected_region):\n",
        "    text = pytesseract.image_to_string(selected_region)\n",
        "    print(\"Detected Text: \", text)\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()\n",
        "\n",
        "# Function to capture a specific region in the active window and call the read_text function\n",
        "def capture_and_read_specific_region():\n",
        "    # Ensure the \"NC_images\" folder exists\n",
        "    if not os.path.exists(nc_images_path):\n",
        "        os.makedirs(nc_images_path)\n",
        "\n",
        "    # Pause for a moment to switch to the desired window\n",
        "    time.sleep(3)  # Adjust this time as needed\n",
        "\n",
        "    # Get the active window\n",
        "    active_window = gw.getActiveWindow()\n",
        "\n",
        "    # Define the specific region coordinates\n",
        "    region_left = 600\n",
        "    region_top = active_window.height - 52 - 850  # 52 pixels above the bottom edge\n",
        "    region_width = 720\n",
        "    region_height = 890\n",
        "\n",
        "    # Set the bounding box to capture the specific region\n",
        "    selected_region = (active_window.left + region_left,\n",
        "                       active_window.top + region_top,\n",
        "                       active_window.left + region_left + region_width,\n",
        "                       active_window.top + region_top + region_height)\n",
        "\n",
        "    # Save the screenshot in the \"NC_images\" folder with a unique name\n",
        "    screenshot_path = os.path.join(nc_images_path, f\"screenshot_{len(os.listdir(nc_images_path)) + 1}.png\")\n",
        "    screenshot = ImageGrab.grab(bbox=selected_region)\n",
        "    screenshot.save(screenshot_path)\n",
        "\n",
        "    # Read the screenshot image\n",
        "    screenshot = cv2.imread(screenshot_path)\n",
        "\n",
        "    # Perform OCR on the selected region\n",
        "    read_text(screenshot)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Narrative Cursor - Text to Speech\")\n",
        "\n",
        "    input(\"Press Enter to start capturing and reading the specific region in the active window:\")\n",
        "\n",
        "    while True:\n",
        "        # Simulate pressing Enter every second (adjust as needed)\n",
        "        keyboard.press_and_release(\"enter\")\n",
        "        time.sleep(1)\n",
        "        capture_and_read_specific_region()"
      ],
      "metadata": {
        "id": "RGeTmFLnIoEJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}